{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deeae641-eb86-4904-bfd7-05ff902f0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_37934/3084354923.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(movies_data_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDb data-5.tsv file\n",
    "movies_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "movies_df = pd.read_csv(movies_data_path, sep='\\t')\n",
    "\n",
    "# Define the new column names\n",
    "new_columns = {\n",
    "    \"tconst\": \"movie_id\",\n",
    "    \"primaryTitle\": \"title\",\n",
    "    \"originalTitle\": \"original_title\",\n",
    "    \"startYear\": \"start_year\",\n",
    "    \"endYear\": \"end_year\",\n",
    "    \"runtimeMinutes\": \"runtime_minutes\",\n",
    "    \"isAdult\": \"is_adult\",\n",
    "    \"averageRating\": \"average_rating\",\n",
    "    \"numVotes\": \"num_votes\"\n",
    "}\n",
    "\n",
    "# Rename columns to match the new column names\n",
    "movies_df = movies_df.rename(columns=new_columns)\n",
    "\n",
    "# Save the Movies table data to a TSV file\n",
    "movies_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\"\n",
    "movies_df.to_csv(movies_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Movies table data saved to:\", movies_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b15140f7-03df-4f66-85d9-f23a1c0d6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the schema for the People table\n",
    "people_schema = {\n",
    "    \"nconst\": \"person_id\",\n",
    "    \"primaryName\": \"name\",\n",
    "    \"birthYear\": \"birth_year\",\n",
    "    \"deathYear\": \"death_year\"\n",
    "}\n",
    "\n",
    "# Load the IMDb name.basics.tsv.gz file\n",
    "people_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data.tsv\"\n",
    "people_df = pd.read_csv(people_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns based on the schema\n",
    "people_columns = list(people_schema.keys())\n",
    "people_table = people_df[people_columns]\n",
    "\n",
    "# Rename columns to match the schema\n",
    "people_table = people_table.rename(columns=people_schema)\n",
    "\n",
    "# Save the People table data to a TSV file\n",
    "people_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv\"\n",
    "people_table.to_csv(people_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"People table data saved to:\", people_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25825ecb-c828-4b9a-985f-e4a44a92f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_41186/3533675592.py:9: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  basics_df = pd.read_csv(basics_data_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CastAndCrew table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.principals.tsv.gz dataset\n",
    "principals_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-7.tsv\"\n",
    "principals_df = pd.read_csv(principals_data_path, sep='\\t')\n",
    "\n",
    "# Load the title.basics.tsv.gz dataset\n",
    "basics_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "basics_df = pd.read_csv(basics_data_path, sep='\\t')\n",
    "\n",
    "# Merge the two datasets on 'tconst' to get 'movie_id'\n",
    "cast_and_crew_df = pd.merge(principals_df, basics_df, on='tconst', how='inner')\n",
    "\n",
    "# Filter the columns\n",
    "cast_and_crew_df = cast_and_crew_df[['tconst', 'nconst', 'category', 'startYear', 'endYear']]\n",
    "\n",
    "# Rename columns\n",
    "cast_and_crew_df.columns = ['movie_id', 'person_id', 'occupation_id', 'start_date', 'end_date']\n",
    "\n",
    "# Save the CastAndCrew table data to a TSV file\n",
    "cast_and_crew_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\"\n",
    "cast_and_crew_df.to_csv(cast_and_crew_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"CastAndCrew table data saved to:\", cast_and_crew_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c93fdd-6772-4149-b9a8-8e99dcc4d2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>occupation_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>nm1588970</td>\n",
       "      <td>self</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>director</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>nm0374658</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>director</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>nm1335271</td>\n",
       "      <td>composer</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id  person_id    occupation_id start_date end_date\n",
       "0  tt0000001  nm1588970             self       1894       \\N\n",
       "1  tt0000001  nm0005690         director       1894       \\N\n",
       "2  tt0000001  nm0374658  cinematographer       1894       \\N\n",
       "3  tt0000002  nm0721526         director       1892       \\N\n",
       "4  tt0000002  nm1335271         composer       1892       \\N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_and_crew_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1a2670-6e85-423a-8078-723159ac43ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Episodes.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.episode.tsv.gz dataset\n",
    "episodes_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-4.tsv\"\n",
    "episodes_df = pd.read_csv(episodes_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns\n",
    "episodes_df = episodes_df[['tconst', 'parentTconst', 'seasonNumber', 'episodeNumber']]\n",
    "\n",
    "# Rename columns\n",
    "# Rename columns\n",
    "episodes_df.columns = ['episode_id', 'parent_movie_id', 'season_number', 'episode_number']\n",
    "\n",
    "\n",
    "# Save the Episodes table data to a TSV file\n",
    "episodes_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Episodes.tsv\"\n",
    "episodes_df.to_csv(episodes_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Episodes table data saved to:\", episodes_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3c77b0-9377-4ebc-81eb-70e0e33822c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.ratings.tsv.gz dataset\n",
    "ratings_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-2.tsv\"\n",
    "ratings_df = pd.read_csv(ratings_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns\n",
    "ratings_df = ratings_df[['tconst', 'averageRating', 'numVotes']]\n",
    "\n",
    "# Rename columns\n",
    "ratings_df.columns = ['movie_id', 'rating_value', 'num_votes']\n",
    "\n",
    "# Add timestamp and source columns\n",
    "ratings_df['rating_timestamp'] = pd.Timestamp.now()\n",
    "ratings_df['rating_source'] = 'IMDb'\n",
    "\n",
    "# Save the Ratings table data to a TSV file\n",
    "ratings_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv\"\n",
    "ratings_df.to_csv(ratings_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Ratings table data saved to:\", ratings_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59917f2-4f40-4048-a445-cd54a79410bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_41186/393316023.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movies.tsv and ratings.tsv\n",
    "movies_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv', sep='\\t')\n",
    "ratings_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv', sep='\\t')\n",
    "\n",
    "# Merge on movie_id\n",
    "merged_df = pd.merge(movies_df, ratings_df, on='movie_id', how='inner')\n",
    "\n",
    "# Select relevant columns and reorder them\n",
    "final_df = merged_df[['movie_id', 'title', 'original_title', 'start_year', 'end_year', 'runtime_minutes', 'is_adult', 'rating_value', 'num_votes']]\n",
    "final_df.columns = ['movie_id', 'title', 'original_title', 'start_year', 'end_year', 'runtime_minutes', 'is_adult', 'average_rating', 'num_votes']\n",
    "\n",
    "# Save the final DataFrame to a new TSV file\n",
    "final_df.to_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies_load.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9907e35-42d7-4ed0-933d-d1980ce37430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.principals.tsv.gz file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-7.tsv'\n",
    "title_principals_df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "# Extract unique occupations from the 'category' column\n",
    "occupations = title_principals_df['category'].unique()\n",
    "\n",
    "# Create a new DataFrame for Occupations with occupation_id and occupation_title\n",
    "occupations_df = pd.DataFrame({'occupation_title': occupations})\n",
    "\n",
    "# Add a new column 'occupation_id' with unique IDs\n",
    "occupations_df['occupation_id'] = range(1, len(occupations_df) + 1)\n",
    "\n",
    "# Reorder the columns\n",
    "occupations_df = occupations_df[['occupation_id', 'occupation_title']]\n",
    "\n",
    "# Save the Occupations DataFrame to a new TSV file\n",
    "occupations_file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Occupations.tsv'\n",
    "occupations_df.to_csv(occupations_file_path, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4170177-f174-4067-82c7-3a04e425a9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_37934/3084354923.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(movies_data_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDb data-5.tsv file\n",
    "movies_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "movies_df = pd.read_csv(movies_data_path, sep='\\t')\n",
    "\n",
    "# Define the new column names\n",
    "new_columns = {\n",
    "    \"tconst\": \"movie_id\",\n",
    "    \"primaryTitle\": \"title\",\n",
    "    \"originalTitle\": \"original_title\",\n",
    "    \"startYear\": \"start_year\",\n",
    "    \"endYear\": \"end_year\",\n",
    "    \"runtimeMinutes\": \"runtime_minutes\",\n",
    "    \"isAdult\": \"is_adult\",\n",
    "    \"averageRating\": \"average_rating\",\n",
    "    \"numVotes\": \"num_votes\"\n",
    "}\n",
    "\n",
    "# Rename columns to match the new column names\n",
    "movies_df = movies_df.rename(columns=new_columns)\n",
    "\n",
    "# Save the Movies table data to a TSV file\n",
    "movies_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\"\n",
    "movies_df.to_csv(movies_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Movies table data saved to:\", movies_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the schema for the People table\n",
    "people_schema = {\n",
    "    \"nconst\": \"person_id\",\n",
    "    \"primaryName\": \"name\",\n",
    "    \"birthYear\": \"birth_year\",\n",
    "    \"deathYear\": \"death_year\"\n",
    "}\n",
    "\n",
    "# Load the IMDb name.basics.tsv.gz file\n",
    "people_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data.tsv\"\n",
    "people_df = pd.read_csv(people_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns based on the schema\n",
    "people_columns = list(people_schema.keys())\n",
    "people_table = people_df[people_columns]\n",
    "\n",
    "# Rename columns to match the schema\n",
    "people_table = people_table.rename(columns=people_schema)\n",
    "\n",
    "# Save the People table data to a TSV file\n",
    "people_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv\"\n",
    "people_table.to_csv(people_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"People table data saved to:\", people_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b27158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_41186/3533675592.py:9: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  basics_df = pd.read_csv(basics_data_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CastAndCrew table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.principals.tsv.gz dataset\n",
    "principals_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-7.tsv\"\n",
    "principals_df = pd.read_csv(principals_data_path, sep='\\t')\n",
    "\n",
    "# Load the title.basics.tsv.gz dataset\n",
    "basics_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "basics_df = pd.read_csv(basics_data_path, sep='\\t')\n",
    "\n",
    "# Merge the two datasets on 'tconst' to get 'movie_id'\n",
    "cast_and_crew_df = pd.merge(principals_df, basics_df, on='tconst', how='inner')\n",
    "\n",
    "# Filter the columns\n",
    "cast_and_crew_df = cast_and_crew_df[['tconst', 'nconst', 'category', 'startYear', 'endYear']]\n",
    "\n",
    "# Rename columns\n",
    "cast_and_crew_df.columns = ['movie_id', 'person_id', 'occupation_id', 'start_date', 'end_date']\n",
    "\n",
    "# Save the CastAndCrew table data to a TSV file\n",
    "cast_and_crew_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\"\n",
    "cast_and_crew_df.to_csv(cast_and_crew_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"CastAndCrew table data saved to:\", cast_and_crew_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Episodes.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.episode.tsv.gz dataset\n",
    "episodes_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-4.tsv\"\n",
    "episodes_df = pd.read_csv(episodes_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns\n",
    "episodes_df = episodes_df[['tconst', 'parentTconst', 'seasonNumber', 'episodeNumber']]\n",
    "\n",
    "# Rename columns\n",
    "# Rename columns\n",
    "episodes_df.columns = ['episode_id', 'parent_movie_id', 'season_number', 'episode_number']\n",
    "\n",
    "\n",
    "# Save the Episodes table data to a TSV file\n",
    "episodes_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Episodes.tsv\"\n",
    "episodes_df.to_csv(episodes_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Episodes table data saved to:\", episodes_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the title.ratings.tsv.gz dataset\n",
    "ratings_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-2.tsv\"\n",
    "ratings_df = pd.read_csv(ratings_data_path, sep='\\t')\n",
    "\n",
    "# Filter the columns\n",
    "ratings_df = ratings_df[['tconst', 'averageRating', 'numVotes']]\n",
    "\n",
    "# Rename columns\n",
    "ratings_df.columns = ['movie_id', 'rating_value', 'num_votes']\n",
    "\n",
    "# Add timestamp and source columns\n",
    "ratings_df['rating_timestamp'] = pd.Timestamp.now()\n",
    "ratings_df['rating_source'] = 'IMDb'\n",
    "\n",
    "# Save the Ratings table data to a TSV file\n",
    "ratings_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv\"\n",
    "ratings_df.to_csv(ratings_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Ratings table data saved to:\", ratings_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_41186/393316023.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movies.tsv and ratings.tsv\n",
    "movies_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv', sep='\\t')\n",
    "ratings_df = pd.read_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Ratings.tsv', sep='\\t')\n",
    "\n",
    "# Merge on movie_id\n",
    "merged_df = pd.merge(movies_df, ratings_df, on='movie_id', how='inner')\n",
    "\n",
    "# Select relevant columns and reorder them\n",
    "final_df = merged_df[['movie_id', 'title', 'original_title', 'start_year', 'end_year', 'runtime_minutes', 'is_adult', 'rating_value', 'num_votes']]\n",
    "final_df.columns = ['movie_id', 'title', 'original_title', 'start_year', 'end_year', 'runtime_minutes', 'is_adult', 'average_rating', 'num_votes']\n",
    "\n",
    "# Save the final DataFrame to a new TSV file\n",
    "final_df.to_csv('/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies_load.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b544eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289fa16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Genre.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDb title.basics.tsv dataset (assuming it is not gzip-compressed)\n",
    "basics_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "basics_df = pd.read_csv(basics_data_path, sep='\\t', usecols=['tconst', 'genres'])\n",
    "\n",
    "# Explode the 'genres' column to create a row for each genre for each movie\n",
    "basics_df['genres'] = basics_df['genres'].str.split(',')  # Convert genres to a list\n",
    "genres_df = basics_df.explode('genres')\n",
    "\n",
    "# Remove duplicates and null values\n",
    "unique_genres = genres_df['genres'].dropna().unique()\n",
    "unique_genres_df = pd.DataFrame(unique_genres, columns=['genre_name'])\n",
    "\n",
    "# Add a genre_id column (auto-incrementing integer)\n",
    "unique_genres_df.reset_index(inplace=True)\n",
    "unique_genres_df.rename(columns={'index': 'genre_id'}, inplace=True)\n",
    "unique_genres_df['genre_id'] += 1  # Optional: Start IDs at 1 instead of 0\n",
    "\n",
    "# Save the Genre table data to a TSV file\n",
    "genre_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Genre.tsv\"\n",
    "unique_genres_df.to_csv(genre_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Genre table data saved to:\", genre_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930728e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieGenres table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/MovieGenres.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDb title.basics.tsv.gz dataset\n",
    "basics_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"  # Update with the actual path\n",
    "basics_df = pd.read_csv(\n",
    "    basics_data_path, \n",
    "    sep='\\t', \n",
    "    usecols=['tconst', 'genres'], \n",
    "    dtype={'tconst': str, 'genres': str}  # Explicitly define data types\n",
    ")\n",
    "\n",
    "# Explode the 'genres' column to create a row for each genre for each movie\n",
    "basics_df['genres'] = basics_df['genres'].str.split(',')  # Convert genres to a list\n",
    "movie_genres_df = basics_df.explode('genres')\n",
    "\n",
    "# Remove null values and reset index\n",
    "movie_genres_df.dropna(subset=['genres'], inplace=True)\n",
    "movie_genres_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load the Genre table with genre_ids and genre_names\n",
    "genre_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Genre.tsv\"\n",
    "genres_df = pd.read_csv(genre_table_path, sep='\\t', dtype={'genre_id': int, 'genre_name': str})\n",
    "\n",
    "# Map genre names in movie_genres_df to genre_ids from genres_df\n",
    "movie_genres_df = movie_genres_df.merge(genres_df, left_on='genres', right_on='genre_name', how='left')\n",
    "\n",
    "# Select and rename columns for the MovieGenres table\n",
    "movie_genres_df = movie_genres_df[['tconst', 'genre_id']]\n",
    "movie_genres_df.columns = ['movie_id', 'genre_id']\n",
    "\n",
    "# Save the MovieGenres table data to a TSV file\n",
    "movie_genres_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/MovieGenres.tsv\"\n",
    "movie_genres_df.to_csv(movie_genres_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"MovieGenres table data saved to:\", movie_genres_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a10a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/3642380994.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  akas_df = pd.read_csv(akas_data_path, sep='\\t', usecols=['titleId', 'ordering', 'title', 'region', 'language', 'types', 'attributes', 'isOriginalTitle'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternateTitles table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/AlternateTitles.tsv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ae6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_3340/564115723.py:15: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  akas_df = pd.read_csv(akas_data_path, sep='\\t', usecols=['titleId', 'ordering', 'title', 'region', 'language', 'types', 'attributes', 'isOriginalTitle'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlternateTitles table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/AlternateTitles.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Function to convert list-like string to PostgreSQL array format\n",
    "def to_pg_array(text):\n",
    "    if pd.isnull(text) or text == '\\\\N':\n",
    "        return '{}'\n",
    "    items = text.split(',')\n",
    "    # Ensure that items are enclosed in double quotes\n",
    "    quoted_items = ','.join(f'\"{item}\"' for item in items if item)\n",
    "    return f'{{{quoted_items}}}'\n",
    "\n",
    "# Load the IMDb title.akas.tsv dataset\n",
    "akas_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-6.tsv\"\n",
    "akas_df = pd.read_csv(akas_data_path, sep='\\t', usecols=['titleId', 'ordering', 'title', 'region', 'language', 'types', 'attributes', 'isOriginalTitle'])\n",
    "\n",
    "# Rename columns to match your schema for AlternateTitles table\n",
    "akas_df.rename(columns={\n",
    "    'titleId': 'movie_id', \n",
    "    'title': 'alternate_title',\n",
    "    'isOriginalTitle': 'is_original_title'\n",
    "}, inplace=True)\n",
    "\n",
    "# Handle missing data if necessary\n",
    "akas_df.fillna({'language': 'unknown', 'region': 'unknown'}, inplace=True)\n",
    "\n",
    "# Convert 'isOriginalTitle' from 0/1 to boolean if not already\n",
    "akas_df['is_original_title'] = akas_df['is_original_title'].astype(bool)\n",
    "\n",
    "# Transform 'types' and 'attributes' to PostgreSQL array format\n",
    "akas_df['types'] = akas_df['types'].apply(to_pg_array)\n",
    "akas_df['attributes'] = akas_df['attributes'].apply(to_pg_array)\n",
    "\n",
    "# Save to TSV\n",
    "alternate_titles_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/AlternateTitles.tsv\"\n",
    "akas_df.to_csv(alternate_titles_path, sep='\\t', index=False, quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "\n",
    "print(\"AlternateTitles table data saved to:\", alternate_titles_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f34d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitleCrew table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/TitleCrew.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "# Load the IMDb title.crew.tsv dataset\n",
    "crew_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-3.tsv\"\n",
    "crew_df = pd.read_csv(crew_data_path, sep='\\t')\n",
    "\n",
    "# Rename columns to match your schema for the TitleCrew table\n",
    "crew_df.rename(columns={\n",
    "    'tconst': 'movie_id',\n",
    "    'directors': 'director_ids',  # Assuming these are lists of director IDs\n",
    "    'writers': 'writer_ids'       # Assuming these are lists of writer IDs\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace any '\\N' values with an empty array representation '{}'\n",
    "crew_df['director_ids'] = crew_df['director_ids'].apply(lambda x: '{}' if x == '\\\\N' else '{' + ','.join(f'\"{item}\"' for item in x.split(',')) + '}')\n",
    "crew_df['writer_ids'] = crew_df['writer_ids'].apply(lambda x: '{}' if x == '\\\\N' else '{' + ','.join(f'\"{item}\"' for item in x.split(',')) + '}')\n",
    "\n",
    "# Save to TSV\n",
    "title_crew_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/TitleCrew.tsv\"\n",
    "crew_df.to_csv(title_crew_path, sep='\\t', index=False, quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "\n",
    "print(\"TitleCrew table data saved to:\", title_crew_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3d1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/3916170585.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  film_roles_df.rename(columns={\n",
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/3916170585.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  film_roles_df['character_name'].replace({'\\\\N': ''}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FilmRoles table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/FilmRoles.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Load the IMDb title.principals.tsv.gz dataset\n",
    "principals_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-7.tsv\"\n",
    "principals_df = pd.read_csv(principals_data_path, sep='\\t')\n",
    "\n",
    "# Filter for relevant columns and rename them\n",
    "film_roles_df = principals_df[['tconst', 'nconst', 'ordering', 'characters']]\n",
    "film_roles_df.rename(columns={\n",
    "    'tconst': 'movie_id',\n",
    "    'nconst': 'person_id',\n",
    "    'characters': 'character_name'\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace NaN or '\\\\N' values with an empty string in the character_name column\n",
    "film_roles_df['character_name'].replace({'\\\\N': ''}, inplace=True)\n",
    "\n",
    "# Save to TSV\n",
    "film_roles_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/FilmRoles.tsv\"\n",
    "film_roles_df.to_csv(film_roles_path, sep='\\t', index=False, quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "\n",
    "print(\"FilmRoles table data saved to:\", film_roles_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee54f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/2903139745.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(movies_data_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies table data saved to: /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDb data-5.tsv file\n",
    "movies_data_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/IMDB Dataset/data-5.tsv\"\n",
    "movies_df = pd.read_csv(movies_data_path, sep='\\t')\n",
    "movies_df = movies_df.drop(columns=['titleType', 'genres'])\n",
    "# Define the new column names\n",
    "new_columns = {\n",
    "    \"tconst\": \"movie_id\",\n",
    "    \"primaryTitle\": \"title\",\n",
    "    \"originalTitle\": \"original_title\",\n",
    "    \"startYear\": \"start_year\",\n",
    "    \"endYear\": \"end_year\",\n",
    "    \"runtimeMinutes\": \"runtime_minutes\",\n",
    "    \"isAdult\": \"is_adult\",\n",
    "    \"averageRating\": \"average_rating\",\n",
    "    \"numVotes\": \"num_votes\"\n",
    "}\n",
    "\n",
    "# Rename columns to match the new column names\n",
    "movies_df = movies_df.rename(columns=new_columns)\n",
    "\n",
    "# Save the Movies table data to a TSV file\n",
    "movies_table_path = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\"\n",
    "movies_df.to_csv(movies_table_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Movies table data saved to:\", movies_table_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62019341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/710275161.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed and file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "input_file = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\"\n",
    "output_file = \"/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv\"\n",
    "\n",
    "# Read the TSV file into a DataFrame\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "# Drop duplicate rows based on all columns\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Save the DataFrame with no duplicates to a new TSV file\n",
    "df_no_duplicates.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(\"Duplicates removed and file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f920c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_44745/1358842782.py:12: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  castandcrew_df = pd.read_csv(castandcrew_path, delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the files\n",
    "people_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv'  # Update the path accordingly\n",
    "castandcrew_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv'  # Update the path accordingly\n",
    "\n",
    "# Read the People.tsv to fetch valid person_ids\n",
    "people_df = pd.read_csv(people_path, delimiter='\\t')\n",
    "valid_person_ids = set(people_df['person_id'])\n",
    "\n",
    "# Read the CastAndCrew.tsv\n",
    "castandcrew_df = pd.read_csv(castandcrew_path, delimiter='\\t')\n",
    "\n",
    "# Filter out rows where 'person_id' is not valid\n",
    "castandcrew_df = castandcrew_df[castandcrew_df['person_id'].isin(valid_person_ids)]\n",
    "\n",
    "# Save the updated CastAndCrew.tsv over the original file\n",
    "castandcrew_df.to_csv(castandcrew_path, sep='\\t', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a5bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_57499/2356992854.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, delimiter='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your TSV file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv'\n",
    "\n",
    "# Load the data from the TSV file\n",
    "data = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "# Group the data by the combination of movie_id, person_id, and occupation_id and count occurrences\n",
    "duplicate_counts = data.groupby(['movie_id', 'person_id', 'occupation_id']).size()\n",
    "\n",
    "# Filter the counts to find combinations that occur more than once\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "\n",
    "# Print out the duplicate combinations and their counts\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1e0717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_57499/2274861261.py:9: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  valid_ids = pd.read_csv(movies_path, delimiter='\\t', on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your TSV files\n",
    "movies_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv'\n",
    "title_crew_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/TitleCrew.tsv'\n",
    "\n",
    "try:\n",
    "    # Load valid movie_ids with appropriate delimiter and handling for bad lines\n",
    "    valid_ids = pd.read_csv(movies_path, delimiter='\\t', on_bad_lines='skip')\n",
    "    valid_movie_ids = set(valid_ids['movie_id'])\n",
    "\n",
    "    # Load the TitleCrew data with the same parameters\n",
    "    title_crew_data = pd.read_csv(title_crew_path, delimiter='\\t', on_bad_lines='skip')\n",
    "\n",
    "    # Filter to keep only rows where the movie_id is in the list of valid movie_ids\n",
    "    filtered_data = title_crew_data[title_crew_data['movie_id'].isin(valid_movie_ids)]\n",
    "\n",
    "    # Save the filtered data back to TSV\n",
    "    filtered_data.to_csv(title_crew_path, sep='\\t', index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error processing the TSV files:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f726b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/hjjt0cc558n2flsm7s_p05n00000gp/T/ipykernel_57499/3602219013.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(movies_path, delimiter='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Entries with invalid movie_ids have been removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the TSV files\n",
    "movies_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv'\n",
    "film_roles_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/FilmRoles.tsv'\n",
    "\n",
    "# Load the valid movie_ids from Movies.tsv\n",
    "movies_df = pd.read_csv(movies_path, delimiter='\\t')\n",
    "valid_movie_ids = set(movies_df['movie_id'])  # Ensure 'movie_id' is the column name\n",
    "\n",
    "# Load the FilmRoles data\n",
    "film_roles_df = pd.read_csv(film_roles_path, delimiter='\\t')\n",
    "\n",
    "# Filter to keep only rows where the movie_id is in the list of valid movie_ids\n",
    "filtered_film_roles_df = film_roles_df[film_roles_df['movie_id'].isin(valid_movie_ids)]\n",
    "\n",
    "# Save the filtered data back to FilmRoles.tsv\n",
    "filtered_film_roles_df.to_csv(film_roles_path, sep='\\t', index=False)\n",
    "\n",
    "print(\"Preprocessing complete. Entries with invalid movie_ids have been removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bed8430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed FILES\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the directory containing your TSV files\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/FilmRoles.tsv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            updated_content = content.replace('\\\\N', 'NULL')\n",
    "\n",
    "            # Write the updated content back to the file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(updated_content)\n",
    "\n",
    "            print(f\"Processed FILES\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923355a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All start_date and end_date values are integers or NULL.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to your TSV file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/CastAndCrew.tsv'\n",
    "\n",
    "# This function checks if the string is an integer or 'NULL'\n",
    "def is_integer_or_null(s):\n",
    "    return s.isdigit() or s == 'NULL'\n",
    "\n",
    "# Initialize a list to keep track of rows with invalid date formats\n",
    "invalid_rows = []\n",
    "\n",
    "# Read the TSV file and check each start_date and end_date\n",
    "with open(file_path, mode='r', encoding='utf-8-sig') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        start_date = row.get('start_date')\n",
    "        end_date = row.get('end_date')\n",
    "        if not (is_integer_or_null(start_date) and is_integer_or_null(end_date)):\n",
    "            invalid_rows.append(row)\n",
    "\n",
    "# If there are invalid rows, print them\n",
    "if invalid_rows:\n",
    "    print(\"Found rows with invalid start_date or end_date:\")\n",
    "    for row in invalid_rows:\n",
    "        print(row)\n",
    "else:\n",
    "    print(\"All start_date and end_date values are integers or NULL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00bfd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All birth_year and death_year values are integers or NULL.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to your TSV file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/People.tsv'\n",
    "\n",
    "# This function checks if the string is an integer or 'NULL'\n",
    "def is_integer_or_null(s):\n",
    "    if s == 'NULL':\n",
    "        return True\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Initialize a list to keep track of rows with invalid date formats\n",
    "invalid_rows = []\n",
    "\n",
    "# Read the TSV file and check each birth_year and death_year\n",
    "with open(file_path, mode='r', encoding='utf-8-sig') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        birth_year = row.get('birth_year')\n",
    "        death_year = row.get('death_year')\n",
    "        if not (is_integer_or_null(birth_year) and is_integer_or_null(death_year)):\n",
    "            invalid_rows.append(row)\n",
    "\n",
    "# If there are invalid rows, print them\n",
    "if invalid_rows:\n",
    "    print(\"Found rows with invalid birth_year or death_year:\")\n",
    "    for row in invalid_rows:\n",
    "        print(row)\n",
    "else:\n",
    "    print(\"All birth_year and death_year values are integers or NULL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36edd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data values are correct. Ready for SQL import.\n",
      "Converted data written to /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to your TSV file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv'\n",
    "\n",
    "# Check if the value is an integer or 'NULL'\n",
    "def is_integer_or_null(s):\n",
    "    return s.isdigit() or s == 'NULL'\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a list to keep track of rows with invalid data\n",
    "invalid_rows = []\n",
    "\n",
    "# List to hold converted rows for potentially writing back to a new TSV\n",
    "converted_rows = []\n",
    "\n",
    "# Read the TSV file and check each relevant field\n",
    "with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if row['is_adult'] is None \\\n",
    "           or not is_integer_or_null(row['start_year']) \\\n",
    "           or not (is_integer_or_null(row['end_year']) or row['end_year'] == 'NULL') \\\n",
    "           or not is_integer_or_null(row['runtime_minutes']):\n",
    "            invalid_rows.append(row)\n",
    "\n",
    "# If there are invalid rows, print them\n",
    "if invalid_rows:\n",
    "    print(\"Found rows with invalid data:\")\n",
    "    for row in invalid_rows:\n",
    "        print(row)\n",
    "else:\n",
    "    print(\"All data values are correct. Ready for SQL import.\")\n",
    "\n",
    "# Optionally, write the converted data back to a new TSV file\n",
    "output_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv'\n",
    "with open(output_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(converted_rows)\n",
    "    print(f\"Converted data written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7813b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data written back to /Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the path to your TSV file\n",
    "file_path = '/Users/pranavpolavarapu/Desktop/SUNY UB ðŸŽ“/Sem 2/DMQL - CSE 560/Team Project/TABLES DATA/Movies.tsv'\n",
    "temp_file_path = file_path + '.tmp'  # Temporary file path\n",
    "\n",
    "# List of movie_ids to exclude from the cleaned file\n",
    "exclude_movie_ids = {\n",
    "    'tt10233364', 'tt10970874', 'tt11670006', 'tt11868642', 'tt12149332',\n",
    "    'tt12415330', 'tt13704268', 'tt27147391', 'tt27404292', 'tt27493617',\n",
    "    'tt27493772', 'tt27675642', 'tt28325562', 'tt28535095', 'tt29081018',\n",
    "    'tt3984412', 'tt9822816', 'tt9909210'\n",
    "}\n",
    "\n",
    "# Read the TSV file and write out only rows with movie_ids not in exclude_movie_ids\n",
    "with open(file_path, mode='r', encoding='utf-8') as infile, \\\n",
    "     open(temp_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "    \n",
    "    writer.writeheader()  # Write the header to the output file\n",
    "    \n",
    "    for row in reader:\n",
    "        if row['movie_id'] not in exclude_movie_ids:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Replace the original file with the modified temporary file\n",
    "os.replace(temp_file_path, file_path)\n",
    "\n",
    "print(f\"Updated data written back to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
